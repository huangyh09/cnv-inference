{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "%aimport cnv_inference_config\n",
    "project_config = cnv_inference_config\n",
    "os.chdir(project_config.MB_ROOT)\n",
    "\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import itertools\n",
    "from itertools import product as cartesian\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "\n",
    "import numba\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import toolkit\n",
    "import util\n",
    "from workspace.workspace_manager import WorkspaceManager\n",
    "\n",
    "sns.set()\n",
    "\n",
    "workspace = {}\n",
    "for data_type in [\"scDNA\", \"scRNA\"]:\n",
    "    workspace.update({ \n",
    "        data_type : WorkspaceManager(\n",
    "            task_name=\"ase_to_cnv\",\n",
    "            experiment_info={\"data\" : data_type},\n",
    "            verbose=True\n",
    "        )\n",
    "    })\n",
    "    workspace[data_type].load_workspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6ccacd88b5406a967e0558fa366fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='scDNA, loading datasets into RAM', max=2, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29059915056a47f58bef40792a8e5ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='scRNA, loading datasets into RAM', max=2, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for data_type in [\"scDNA\", \"scRNA\"]:\n",
    "    data[data_type] = {\n",
    "        data_name :\n",
    "        util.pickle_load(data_dump)\n",
    "        for data_name, data_dump in tqdm_notebook(\n",
    "            workspace[data_type].tmp_data.items(),\n",
    "            f\"{data_type}, loading datasets into RAM\"\n",
    "        )\n",
    "    }\n",
    "    \n",
    "for modality in [\"scDNA\", \"scRNA\"]:\n",
    "    data[modality][\"block_counts\"].rename(\n",
    "        columns={\"GENE_ID\" : \"BLOCK_ID\"}, \n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets have 8776 blocks in common\n"
     ]
    }
   ],
   "source": [
    "common_blocks = (set(data[\"scDNA\"][\"block_counts\"].BLOCK_ID) \n",
    "                & set(data[\"scRNA\"][\"block_counts\"].BLOCK_ID))\n",
    "\n",
    "print(\"Datasets have {} blocks in common\".format(len(common_blocks)))\n",
    "\n",
    "for modality in workspace.keys():\n",
    "    data[modality][\"block_counts\"] = util.filter_by_isin(\n",
    "        data[modality][\"block_counts\"], \n",
    "        \"BLOCK_ID\", \n",
    "        common_blocks\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "common_block_ids = data[\"scDNA\"][\"block_counts\"][\"BLOCK_ID\"].values.astype(int)\n",
    "    \n",
    "assert (data[\"scDNA\"][\"block_counts\"].shape[0] \n",
    "        == data[\"scRNA\"][\"block_counts\"].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_prime = toolkit.extract_barcodes(data[\"scDNA\"][\"block_counts\"]).size\n",
    "M = data[\"scRNA\"][\"clustering\"][\"LABEL\"].unique().size \n",
    "# M = toolkit.extract_barcodes(data[\"scRNA\"][\"block_counts\"]).size\n",
    "K = data[\"scDNA\"][\"clustering\"][\"LABEL\"].unique().size\n",
    "N_G = data[\"scDNA\"][\"block_counts\"].shape[0]\n",
    "T_max = 5\n",
    "tau = np.concatenate([[(t - k, k) for k in range(t + 1)] \n",
    "                      for t in range(1, T_max +1)])\n",
    "conf_to_num = {tuple(cnv_config) : i for i, cnv_config in enumerate(tau)}\n",
    "num_to_conf = {val : key for key, val in conf_to_num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_G_prime = toolkit.extract_counts(data[\"scDNA\"][\"block_counts\"]).values\n",
    "D_G = toolkit.extract_counts(\n",
    "    toolkit.aggregate_by_barcode_groups(\n",
    "        data[\"scRNA\"][\"block_counts\"],\n",
    "        data[\"scRNA\"][\"clustering\"]\n",
    "    )\n",
    ").values\n",
    "\n",
    "A_G_prime = toolkit.extract_counts(\n",
    "    data[\"scDNA\"][\"block_counts\"], \n",
    "    suffix=\"ad\"\n",
    ").values\n",
    "A_G = toolkit.extract_counts(\n",
    "    toolkit.aggregate_by_barcode_groups(\n",
    "        data[\"scRNA\"][\"block_counts\"], \n",
    "        data[\"scRNA\"][\"clustering\"]\n",
    "    ),\n",
    "    suffix=\"ad\"\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data[\"scDNA\"][\"clustering\"][\"LABEL\"].value_counts().sort_index().values / M_prime\n",
    "assert np.isclose(f.sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ab2aed3d94e19aa804928665257dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='reading CNV information', max=9, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 4.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "(18011, 4) 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rodata_dir = \"/icgc/dkfzlsdf/analysis/B260/users/v390v/cnv_inference/data/raw/first_sample\"\n",
    "CNV_prime = []\n",
    "for i in tqdm_notebook(range(9), \"reading CNV information\"):\n",
    "    snp_cnv = pd.read_csv(\n",
    "        f\"{rodata_dir}/TabHaplotypeblock_with_phasedSNPs_{i + 1}.bed\", \n",
    "        usecols=[0, 1, 2, 3],\n",
    "        names=[\"CHROM\", \"START\", \"END\", \"CNV\"],\n",
    "        sep='\\t'\n",
    "    )\n",
    "    snp_cnv.drop_duplicates(inplace=True)\n",
    "    print(snp_cnv.shape, np.median(snp_cnv[\"CNV\"]))\n",
    "    CNV_prime.append(snp_cnv[\"CNV\"].values.astype(int))\n",
    "CNV_prime = np.column_stack(CNV_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(CNV_prime, cmap=\"BuGn_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"scDNA\"][\"clonal_block_counts\"] = toolkit.aggregate_by_barcode_groups(\n",
    "    data[\"scDNA\"][\"block_counts\"],\n",
    "    data[\"scDNA\"][\"clustering\"]\n",
    ")\n",
    "\n",
    "D_C_prime = toolkit.extract_counts(\n",
    "    data[\"scDNA\"][\"clonal_block_counts\"]\n",
    ").values\n",
    "A_C_prime = toolkit.extract_counts(\n",
    "    data[\"scDNA\"][\"clonal_block_counts\"], \"ad\"\n",
    ").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def beta_mode(a, b):\n",
    "    return (a - 1) / (a + b - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = np.full_like(D_C_prime, np.nan)\n",
    "for block_id, clone_id in tqdm_notebook(cartesian(range(N_G), range(K))):\n",
    "    t = CNV_prime[block_id, clone_id]\n",
    "    ad = A_C_prime[block_id, clone_id]\n",
    "    dp = D_C_prime[block_id, clone_id]\n",
    "    if dp == 0 or dp is np.nan:\n",
    "        continue\n",
    "    ase_ratio = ad / dp\n",
    "    offset = np.argmin(np.abs(np.arange(t + 1) / t - ase_ratio))\n",
    "    T[block_id, clone_id] = int(conf_to_num[(t, 0)] + offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee6dc93c2ca49eea25d4ab461479c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ASE ratios are stored as (\\alpha, \\beta) parameter tuples\n",
    "# of the underlying Beta distributions\n",
    "Alpha_G = np.zeros(shape=(N_G, tau.shape[0]))\n",
    "Beta_G = np.zeros(shape=(N_G, tau.shape[0]))\n",
    "Theta_G = np.zeros(shape=(N_G, tau.shape[0])) \n",
    "\n",
    "eps = 1\n",
    "for block_id, cnv_config in tqdm_notebook(itertools.product(range(N_G), tau)):\n",
    "    k0, k1 = cnv_config\n",
    "    t = k0 + k1\n",
    "    \n",
    "    if k0 == 0:\n",
    "        alpha, beta = 1, 1 + eps\n",
    "    elif k1 == 0:\n",
    "        alpha, beta = 1 + eps, 1\n",
    "    else:\n",
    "        if k1 > k0:\n",
    "            alpha = 1 + eps\n",
    "            beta = k1 / k0 * alpha + (k0 - k1) / k0\n",
    "        else:\n",
    "            beta = 1 + eps\n",
    "            alpha = k0 / k1 * beta + (k1 - k0) / k1\n",
    "        assert np.isclose(beta_mode(alpha, beta), k0 / t)\n",
    "    \n",
    "    assert alpha >= 1 and beta >= 1\n",
    "    config_id = conf_to_num[tuple(cnv_config)]\n",
    "    Alpha_G[block_id, config_id] = alpha\n",
    "    Beta_G[block_id, config_id] = beta\n",
    "    Theta_G[block_id, config_id] = k0 / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_logit(cell_id, A, D, X):\n",
    "    ok_mask = ~(np.isnan(D) | (D == 0))\n",
    "    probas = sps.binom(\n",
    "        n=D[ok_mask], \n",
    "        p=X[ok_mask]\n",
    "    ).pmf(A[ok_mask])\n",
    "    return np.sum(np.log(probas[probas > 0]))\n",
    "\n",
    "\n",
    "def cell_likelihood(cell_id, A, D, X):\n",
    "    return np.exp(cell_logit(cell_id, A, D, X)).prod()\n",
    "\n",
    "\n",
    "def cell_loglikelihood(cell_id, A, D, X):\n",
    "    return cell_logit(cell_id, A, D, X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_I_G(cell_id, Theta_G):\n",
    "    logprobas = np.array([\n",
    "        cell_loglikelihood(\n",
    "            cell_id, \n",
    "            A_G[:, cell_id], \n",
    "            D_G[:, cell_id], \n",
    "            Theta_G[:, clone_id]\n",
    "        ) \n",
    "        + np.log(f[clone_id])\n",
    "        for clone_id in range(K)\n",
    "    ])\n",
    "#     print(f\"{cell_id}:\\t {logprobas}\")\n",
    "    return sps.rv_discrete(\n",
    "       a=0, b=K, \n",
    "       values=[np.arange(K), np.abs(logprobas) / np.nansum(np.abs(logprobas))]\n",
    "    ).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8db2f997a11400e9890b821f6abaec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='updating I_G', max=10, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'update_I_G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-064d40453212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m I_G = np.array(Parallel(16)(\n\u001b[1;32m      3\u001b[0m     \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_I_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcell_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"updating I_G\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ))\n",
      "\u001b[0;32m/icgc/dkfzlsdf/analysis/B260/users/v390v/.conda/envs/xclone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/icgc/dkfzlsdf/analysis/B260/users/v390v/.conda/envs/xclone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    752\u001b[0m             tasks = BatchedCalls(itertools.islice(iterator, batch_size),\n\u001b[1;32m    753\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nested_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                                  self._pickle_cache)\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/icgc/dkfzlsdf/analysis/B260/users/v390v/.conda/envs/xclone/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice, backend_and_jobs, pickle_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_and_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-064d40453212>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m I_G = np.array(Parallel(16)(\n\u001b[1;32m      3\u001b[0m     \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_I_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTheta_G\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcell_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"updating I_G\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'update_I_G' is not defined"
     ]
    }
   ],
   "source": [
    "I_G_prime = data[\"scDNA\"][\"clustering\"][\"LABEL\"].astype(int).values - 1 # to zero-indexing\n",
    "I_G = np.array(Parallel(16)(\n",
    "    delayed(update_I_G)(cell_id, Theta_G)\n",
    "    for cell_id in tqdm_notebook(range(M), \"updating I_G\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91f1e57b0fd4b4aa3852b576472b9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='updating H_G and X_G', max=268, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494ba42ffadd45afaf10c3793834ce1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='updating H_G and X_G', max=10, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "H_G_prime = np.full_like(D_G_prime, np.nan)\n",
    "X_G_prime = np.full_like(D_G_prime, np.nan)\n",
    "for cell_id in tqdm_notebook(range(M_prime), \"updating H_G and X_G\"):\n",
    "    H_G_prime[:, cell_id] = T[:, I_G_prime[cell_id]]\n",
    "    not_na_mask = ~np.isnan(H_G_prime[:, cell_id])\n",
    "    X_G_prime[not_na_mask, cell_id] = Theta_G[\n",
    "        not_na_mask, \n",
    "        H_G_prime[not_na_mask, cell_id].astype(int)\n",
    "    ]\n",
    "\n",
    "H_G = np.full_like(D_G, np.nan)\n",
    "X_G = np.full_like(D_G, np.nan)\n",
    "for cell_id in tqdm_notebook(range(M), \"updating H_G and X_G\"):\n",
    "    H_G[:, cell_id] = T[:, I_G[cell_id]]\n",
    "    not_na_mask = ~np.isnan(H_G[:, cell_id])\n",
    "    X_G[not_na_mask, cell_id] = Theta_G[\n",
    "        not_na_mask, \n",
    "        H_G[not_na_mask, cell_id].astype(int)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(labels, title, outfile=None, show=True):\n",
    "                \n",
    "        sns.set(style=\"whitegrid\", font_scale=1.5);\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(20,30))\n",
    "        ax[0].set_title(\"Cluster label assigned by XClone\", fontsize=20)\n",
    "        sns.countplot(\n",
    "            labels, \n",
    "            palette=#sns.color_palette(\"muted\", \n",
    "                      #                n_colors=np.unique(labels).size),\n",
    "            {\n",
    "#                 \"1\" : \"#3182bd\", #\"C0\",\n",
    "#                 \"2\" : \"#2ca25f\", #\"C2\",\n",
    "#                 \"3\" : \"#feb24c\"#\"C1\"\n",
    "                1 : \"xkcd:orange\",\n",
    "                2 : \"xkcd:azure\",\n",
    "                3 : \"xkcd:cyan\",\n",
    "                4 : \"xkcd:yellow\",\n",
    "                5 : \"xkcd:blue\",\n",
    "                6 : \"xkcd:red\",\n",
    "                7 : \"xkcd:pink\",\n",
    "                8 : \"xkcd:grey\",\n",
    "                9 : \"xkcd:black\"\n",
    "            },\n",
    "            ax=ax[0]\n",
    "        )\n",
    "\n",
    "    \n",
    "        ax[1].set_title(title)\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            x=\"TSNE_1\", y=\"TSNE_2\", \n",
    "            hue=labels, \n",
    "            data=data[\"scRNA\"][\"clustering\"], \n",
    "            legend=\"full\",\n",
    "            palette=#sns.color_palette(\"muted\", \n",
    "                     #                 n_colors=np.unique(labels).size),\n",
    "            {\n",
    "#                 1 : \"#3182bd\", #\"C0\",\n",
    "#                 2 : \"#2ca25f\", #\"C2\",\n",
    "#                 3 : \"#feb24c\"#\"C1\"\n",
    "                1 : \"xkcd:orange\",\n",
    "                2 : \"xkcd:azure\",\n",
    "                3 : \"xkcd:cyan\",\n",
    "                4 : \"xkcd:yellow\",\n",
    "                5 : \"xkcd:blue\",\n",
    "                6 : \"xkcd:red\",\n",
    "                7 : \"xkcd:pink\",\n",
    "                8 : \"xkcd:grey\",\n",
    "                9 : \"xkcd:black\"\n",
    "            },\n",
    "            ax=ax[1]\n",
    "        );\n",
    "        ax[1].legend().get_frame().set_facecolor(\"white\");\n",
    "        ax[1].legend(frameon=False, bbox_to_anchor=(1,0.5), loc=\"center left\")\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        if outfile is not None:\n",
    "            fig.savefig(outfile, format=outfile.split('.')[-1], dpi=300)\n",
    "        if show == True:\n",
    "            plt.show()\n",
    "        plt.close()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.791759</td>\n",
       "      <td>1.791746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.178054</td>\n",
       "      <td>3.178047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.787492</td>\n",
       "      <td>4.787488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.579251</td>\n",
       "      <td>6.579249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.525161</td>\n",
       "      <td>8.525160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.604603</td>\n",
       "      <td>10.604602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.801827</td>\n",
       "      <td>12.801827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.104413</td>\n",
       "      <td>15.104412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.502308</td>\n",
       "      <td>17.502307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.987214</td>\n",
       "      <td>19.987214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22.552164</td>\n",
       "      <td>22.552164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.191221</td>\n",
       "      <td>25.191221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27.899271</td>\n",
       "      <td>27.899271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.671860</td>\n",
       "      <td>30.671860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33.505073</td>\n",
       "      <td>33.505073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.395445</td>\n",
       "      <td>36.395445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.339884</td>\n",
       "      <td>39.339884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42.335616</td>\n",
       "      <td>42.335616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1\n",
       "0    0.000000  -0.000143\n",
       "1    0.693147   0.693113\n",
       "2    1.791759   1.791746\n",
       "3    3.178054   3.178047\n",
       "4    4.787492   4.787488\n",
       "5    6.579251   6.579249\n",
       "6    8.525161   8.525160\n",
       "7   10.604603  10.604602\n",
       "8   12.801827  12.801827\n",
       "9   15.104413  15.104412\n",
       "10  17.502308  17.502307\n",
       "11  19.987214  19.987214\n",
       "12  22.552164  22.552164\n",
       "13  25.191221  25.191221\n",
       "14  27.899271  27.899271\n",
       "15  30.671860  30.671860\n",
       "16  33.505073  33.505073\n",
       "17  36.395445  36.395445\n",
       "18  39.339884  39.339884\n",
       "19  42.335616  42.335616"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fact(n):\n",
    "    return np.prod(np.arange(n) + 1)\n",
    "\n",
    "pd.DataFrame([[np.log(fact(n)) for n in range(1, 21)], [logfact(n) for n in range(1, 21)]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 s, sys: 0 ns, total: 2.34 s\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "def cell_logit(cell_id, A, D, X):\n",
    "    logits = sps.binom(\n",
    "        n=D, \n",
    "        p=X\n",
    "    ).logpmf(A)\n",
    "    return logits[np.isfinite(logits)]\n",
    "\n",
    "\n",
    "def cell_likelihood(cell_id, A, D, X):\n",
    "    return np.exp(cell_logit(cell_id, A, D, X)).prod()\n",
    "\n",
    "\n",
    "def cell_loglikelihood(cell_id, A, D, X):\n",
    "    return cell_logit(cell_id, A, D, X).sum()\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def logfact(n):\n",
    "    # https://math.stackexchange.com/questions/138194/approximating-log-of-factorial\n",
    "    return n * np.log(n) - n + np.log(n  * ( 1 + 4 * n * (1 + 2 * n) )) / 6 + np.log(np.pi) / 2\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def total_loglikelihood(A_G_prime, R_G_prime, X_G_prime, bincoeff_prime, \n",
    "                        A_G, R_G, X_G, bincoeff):\n",
    "    \n",
    "    alt_prime = A_G_prime * np.log(X_G_prime)\n",
    "    ref_prime = R_G_prime * np.log(1 - X_G_prime)\n",
    "    \n",
    "    alt = A_G * np.log(X_G)\n",
    "    ref = R_G * np.log(1 - X_G)\n",
    "    \n",
    "    loglik_prime = np.ravel(alt_prime + ref_prime + bincoeff_prime)\n",
    "    loglik = np.ravel(alt + ref + bincoeff)\n",
    "\n",
    "    return (\n",
    "        np.sum(loglik_prime[np.isfinite(loglik_prime)])\n",
    "        + np.sum(loglik[np.isfinite(loglik)])\n",
    "    )\n",
    "#     M_prime, M = A_G_prime.shape[1], A_G.shape[1]\n",
    "#     logits_prime = sps.binom(\n",
    "#         n=D_G_prime, \n",
    "#         p=X_G_prime\n",
    "#     ).logpmf(A_G_prime)\n",
    "#     logits = sps.binom(\n",
    "#         n=D_G, \n",
    "#         p=X_G\n",
    "#     ).logpmf(A_G)\n",
    "#     return np.sum(logits_prime[np.isfinite(logits_prime)]) \\\n",
    "#             + np.sum(logits[np.isfinite(logits)])\n",
    "#     return (\n",
    "#         np.sum([\n",
    "#             cell_loglikelihood(cell_id, A_G_prime[:, cell_id], D_G_prime[:, cell_id], X_G_prime[:, cell_id])\n",
    "#             for cell_id in range(M_prime)\n",
    "#         ]) + np.sum([\n",
    "#             cell_loglikelihood(cell_id, A_G[:, cell_id], D_G[:, cell_id], X_G[:, cell_id])\n",
    "#             for cell_id in range(M)\n",
    "#         ])   \n",
    "#     )\n",
    "    \n",
    "    \n",
    "class XClone:\n",
    "    def __init__(self, A_G_prime, D_G_prime, A_G, D_G, I_G_prime, CNV_prime, T_max):\n",
    "        assert A_G_prime.shape == D_G_prime.shape\n",
    "        assert A_G.shape == D_G.shape\n",
    "        assert A_G.shape[0] == A_G_prime.shape[0]\n",
    "        \n",
    "        self.A_G_prime = np.nan_to_num(A_G_prime.astype(np.float64))\n",
    "        self.D_G_prime = np.nan_to_num(D_G_prime.astype(np.float64))\n",
    "        self.R_G_prime = D_G_prime - A_G_prime\n",
    "        self.M_prime = A_G_prime.shape[1]\n",
    "        self.A_G = np.nan_to_num(A_G.astype(np.float64))\n",
    "        self.D_G = np.nan_to_num(D_G.astype(np.float64))\n",
    "        self.R_G = D_G - A_G\n",
    "        self.M = A_G.shape[1] \n",
    "        self.N_G = A_G.shape[0]\n",
    "        \n",
    "        self.I_G_prime = I_G_prime.astype(np.int64)\n",
    "        self.clones, self.f = np.unique(I_G_prime, return_counts=True)\n",
    "        self.K = self.clones.size\n",
    "        self.f = self.f / self.M_prime\n",
    "        assert np.isclose(self.f.sum(), 1)\n",
    "        self.I_G = sps.rv_discrete(\n",
    "           a=0, b=self.K, \n",
    "           values=[np.arange(self.K), self.f]\n",
    "        ).rvs(size=self.M)\n",
    "        \n",
    "        colsum_fn = lambda mx: np.sum(mx, axis=1)\n",
    "        self.D_C_prime = self._group_by_clone(self.D_G_prime, colsum_fn)\n",
    "        self.A_C_prime = self._group_by_clone(self.A_G_prime, colsum_fn)\n",
    "        \n",
    "        self.CNV_prime = CNV_prime\n",
    "        self.T_max = T_max\n",
    "        self.CNV_prime[self.CNV_prime > T_max] = T_max\n",
    "        self.tau = np.concatenate([[(t - k, k) for k in range(t + 1)] \n",
    "                                   for t in range(1, T_max +1)])\n",
    "        self.conf_to_num = {tuple(cnv_config) : i \n",
    "                            for i, cnv_config in enumerate(self.tau)}\n",
    "        self.num_to_conf = {val : key \n",
    "                            for key, val in self.conf_to_num.items()} \n",
    "        self.T = XClone._init_T(\n",
    "            A_C_prime=self.A_C_prime, \n",
    "            D_C_prime=self.D_C_prime, \n",
    "            CNV_prime=self.CNV_prime, \n",
    "            N_G=self.N_G, \n",
    "            K=self.K\n",
    "        )\n",
    "        \n",
    "        self.Alpha_G, self.Beta_G = XClone._init_alpha_beta(self.N_G, self.tau)\n",
    "        self.Theta_G = sps.beta(a=self.Alpha_G, b=self.Beta_G).rvs(\n",
    "            size=(self.Alpha_G.shape)\n",
    "        )\n",
    "        \n",
    "        self.H_G_prime, self.X_G_prime = XClone._init_H_X(\n",
    "            N=self.N_G, \n",
    "            M=self.M_prime, \n",
    "            I=self.I_G_prime,\n",
    "            T=self.T, \n",
    "            Theta_G=self.Theta_G\n",
    "        )\n",
    "        \n",
    "        self.H_C_prime, self.X_C_prime = XClone._init_H_X(\n",
    "            N=self.N_G, \n",
    "            M=self.K, \n",
    "            I=np.arange(self.K),\n",
    "            T=self.T, \n",
    "            Theta_G=self.Theta_G\n",
    "        )\n",
    "    \n",
    "        self.H_G, self.X_G = XClone._init_H_X(\n",
    "            N=self.N_G, \n",
    "            M=self.M, \n",
    "            I=self.I_G,\n",
    "            T=self.T, \n",
    "            Theta_G=self.Theta_G\n",
    "        )\n",
    "        \n",
    "        self.iter_count = 0\n",
    "        \n",
    "        self.bincoeff_prime = logfact(self.D_G_prime) - logfact(self.A_G_prime) - logfact(self.R_G_prime)\n",
    "        self.bincoeff = logfact(self.D_G) - logfact(self.A_G) - logfact(self.R_G)\n",
    "    \n",
    "        \n",
    "    def _group_by_clone(self, mx, agg_fn):\n",
    "        return np.column_stack(\n",
    "            agg_fn(mx[:, self.I_G_prime == k])\n",
    "            for k in self.clones\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True)\n",
    "    def _init_T(A_C_prime, D_C_prime, CNV_prime, N_G, K):\n",
    "        T = np.full((N_G, K), np.nan, dtype=np.float64)\n",
    "        for clone_id in range(K):\n",
    "            for block_id in range(N_G):\n",
    "                t = CNV_prime[block_id, clone_id]\n",
    "                ad = A_C_prime[block_id, clone_id]\n",
    "                dp = D_C_prime[block_id, clone_id]\n",
    "                if dp == 0 or dp is np.nan:\n",
    "                    continue\n",
    "                ase_ratio = ad / dp\n",
    "                offset = np.argmin(np.abs(np.arange(t + 1) / t - ase_ratio))\n",
    "                T[block_id, clone_id] = (t * (t + 1) // 2 - 1) + offset\n",
    "        return T\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True)\n",
    "    def _init_alpha_beta(N_G, tau):\n",
    "        # ASE ratios are stored as (\\alpha, \\beta) parameter tuples\n",
    "        # of the underlying Beta distributions\n",
    "        Alpha_G = np.zeros(shape=(N_G, tau.shape[0]), dtype=np.float64)\n",
    "        Beta_G = np.zeros(shape=(N_G, tau.shape[0]), dtype=np.float64)\n",
    "\n",
    "        eps = 1\n",
    "        for config_id in range(tau.shape[0]):\n",
    "            for block_id in range(N_G):\n",
    "                \n",
    "                k0, k1 = tau[config_id]\n",
    "                t = k0 + k1\n",
    "\n",
    "                if k0 == 0:\n",
    "                    alpha, beta = 1, 1 + eps\n",
    "                elif k1 == 0:\n",
    "                    alpha, beta = 1 + eps, 1\n",
    "                else:\n",
    "                    if k1 > k0:\n",
    "                        alpha = 1 + eps\n",
    "                        beta = k1 / k0 * alpha + (k0 - k1) / k0\n",
    "                    else:\n",
    "                        beta = 1 + eps\n",
    "                        alpha = k0 / k1 * beta + (k1 - k0) / k1\n",
    "    #                 assert np.isclose(beta_mode(alpha, beta), k0 / t)\n",
    "\n",
    "    #             assert alpha >= 1 and beta >= 1\n",
    "                config_id = (t * (t + 1) // 2 - 1) + k1\n",
    "                Alpha_G[block_id, config_id] = alpha\n",
    "                Beta_G[block_id, config_id] = beta\n",
    "        return Alpha_G, Beta_G\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True)\n",
    "    def _init_H_X(N, M, T, I, Theta_G):\n",
    "        H = np.full((N, M), np.nan, dtype=np.float64)\n",
    "        X = np.full((N, M), np.nan, dtype=np.float64)\n",
    "        \n",
    "        for cell_id in range(M):\n",
    "            for block_id in range(N):\n",
    "                H[block_id, cell_id] = T[block_id, I[cell_id]]\n",
    "                if ~np.isnan(H[block_id, cell_id]):\n",
    "                    X[block_id, cell_id] = Theta_G[\n",
    "                        block_id, \n",
    "                        int(H[block_id, cell_id])\n",
    "                    ]\n",
    "        return H, X\n",
    "        \n",
    "    @staticmethod\n",
    "    def _predict_cell_label(cell_id, A, D, X_C_prime, f):\n",
    "        K = X_C_prime.shape[1]    \n",
    "        logprobas = np.array([\n",
    "            cell_loglikelihood(\n",
    "                cell_id, \n",
    "                A[:, cell_id], \n",
    "                D[:, cell_id], \n",
    "                X_C_prime[:, clone_id]\n",
    "            ) \n",
    "            + np.log(f[clone_id])\n",
    "            for clone_id in range(K)\n",
    "        ])\n",
    "        return sps.rv_discrete(\n",
    "           a=0, b=K, \n",
    "           values=[np.arange(K), \n",
    "                   np.abs(logprobas) / np.nansum(np.abs(logprobas))]\n",
    "        ).rvs()\n",
    "\n",
    "    @staticmethod\n",
    "    def _update_I_G(A, D, X_C_prime, f):\n",
    "        return np.array([\n",
    "            XClone._predict_cell_label(cell_id, A, D, X_C_prime, f)\n",
    "            for cell_id in range(A.shape[1])\n",
    "        ])\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True, parallel=True)\n",
    "    def _update_alpha_beta(tau, Theta_G, Alpha_G, Beta_G, A_G, D_G, H_G, changed_mask):\n",
    "        N_G = Alpha_G.shape[0]\n",
    "        new_Alpha_G = np.full_like(Alpha_G, np.nan)\n",
    "        new_Beta_G = np.full_like(Beta_G, np.nan)\n",
    "        \n",
    "        A_changed = A_G[:, changed_mask]\n",
    "        D_changed = D_G[:, changed_mask]\n",
    "        H_changed = D_G[:, changed_mask]\n",
    "        \n",
    "        for cnv_code in range(tau.shape[0]):\n",
    "            h_mask = H_changed == cnv_code\n",
    "\n",
    "            alpha = Alpha_G[:, cnv_code]\n",
    "            beta = Alpha_G[:, cnv_code]\n",
    "\n",
    "            u = np.sum(A_changed * h_mask, axis=1)\n",
    "            v = np.sum((D_changed - A_changed) * h_mask, axis=1)\n",
    "\n",
    "            new_Alpha_G[:, cnv_code] = alpha + u\n",
    "            new_Beta_G[:, cnv_code] = beta + v\n",
    "                \n",
    "        return new_Alpha_G, new_Beta_G\n",
    "    \n",
    "    \n",
    "    def do_gibbs_sampling(self, n_iters):\n",
    "        t0 = time()\n",
    "        self.best_loglik = total_loglikelihood(\n",
    "            self.A_G_prime, self.R_G_prime, self.X_G_prime, self.bincoeff_prime,\n",
    "            self.A_G, self.R_G, self.X_G, self.bincoeff\n",
    "        )\n",
    "        print(f\"Init loglik time: {time() - t0}\")\n",
    "        for iter_count in tqdm_notebook(range(n_iters)):\n",
    "#             t0 = time()\n",
    "            new_I_G = XClone._update_I_G(\n",
    "                A=self.A_G,\n",
    "                D=self.D_G,\n",
    "                X_C_prime=self.X_C_prime,\n",
    "                f=self.f\n",
    "            )\n",
    "            changed_mask = new_I_G != self.I_G\n",
    "#             print(f\"Label sampling time: {time() - t0}\")\n",
    "#             t0 = time()\n",
    "            new_Alpha_G, new_Beta_G = XClone._update_alpha_beta(\n",
    "                tau=self.tau,\n",
    "                Theta_G=self.Theta_G,\n",
    "                Alpha_G=self.Alpha_G,\n",
    "                Beta_G=self.Beta_G,\n",
    "                A_G=self.A_G,\n",
    "                D_G=self.D_G,\n",
    "                H_G=self.H_G,\n",
    "                changed_mask=changed_mask\n",
    "            )\n",
    "            new_Theta_G = sps.beta(a=new_Alpha_G, b=new_Beta_G).rvs(\n",
    "                size=self.Theta_G.shape\n",
    "            )\n",
    "#             print(f\"Posterior update time: {time() - t0}\")\n",
    "#             t0 = time()\n",
    "            new_H_G_prime, new_X_G_prime = XClone._init_H_X(\n",
    "                N=self.N_G, \n",
    "                M=self.M_prime, \n",
    "                I=self.I_G_prime,\n",
    "                T=self.T, \n",
    "                Theta_G=new_Theta_G\n",
    "            )\n",
    "\n",
    "            new_H_G, new_X_G = XClone._init_H_X(\n",
    "                N=self.N_G, \n",
    "                M=self.M, \n",
    "                I=new_I_G,\n",
    "                T=self.T, \n",
    "                Theta_G=new_Theta_G\n",
    "            )\n",
    "#             print(f\"Update time: {time() - t0}\")\n",
    "#             t0 = time()\n",
    "            new_loglik = total_loglikelihood(\n",
    "                self.A_G_prime, self.R_G_prime, new_X_G_prime, self.bincoeff_prime,\n",
    "                self.A_G, self.R_G, new_X_G, self.bincoeff\n",
    "            )\n",
    "    \n",
    "            if new_loglik > self.best_loglik:\n",
    "                print(f\"Iteration {iter_count} — labelling update!\")\n",
    "                print(self.best_loglik, new_loglik)\n",
    "                \n",
    "                self.best_loglik = new_loglik\n",
    "                self.Alpha_G = new_Alpha_G\n",
    "                self.Beta_G = new_Beta_G\n",
    "                self.Theta_G = new_Theta_G\n",
    "                \n",
    "                self.I_G = new_I_G\n",
    "                self.H_G = new_H_G\n",
    "                self.X_G = new_X_G\n",
    "                \n",
    "                self.H_G_prime = new_H_G_prime\n",
    "                self.X_G_prime = new_X_G_prime\n",
    "                \n",
    "                self.H_C_prime, self.X_C_prime = XClone._init_H_X(\n",
    "                    N=self.N_G, \n",
    "                    M=self.K, \n",
    "                    I=np.arange(self.K),\n",
    "                    T=self.T, \n",
    "                    Theta_G=self.Theta_G\n",
    "                )\n",
    "        \n",
    "                classification_report(\n",
    "                    data[\"scRNA\"][\"clustering\"].LABEL.apply(lambda i: self.I_G[i] + 1),#I_G + 1,\n",
    "                    title=f\"XClone label assignment, iteration {self.iter_count},\"\\\n",
    "                            f\" negloglikelihood {np.abs(self.best_loglik)}, \"\n",
    "                            f\"{round(100 * np.mean(changed_mask), 2) }% cells reassigned on last iter\\n\"\\\n",
    "                            \"evo_dist_9 clustering of scDNA, \"\\\n",
    "                            \"seurat clustering of scRNA, \"\\\n",
    "                            f\"{self.N_G} haplotype blocks\",\n",
    "                    outfile=f\"{workspace['scRNA'].img_dir}/xclone/16_10_2019/\"\\\n",
    "                            f\"{np.abs(self.best_loglik)}_{changed_mask.mean()}_{self.iter_count}.png\",\n",
    "                    show=False\n",
    "                )\n",
    "            \n",
    "            self.iter_count += 1\n",
    "\n",
    "\n",
    "T_max = 5\n",
    "I_G_prime = data[\"scDNA\"][\"clustering\"][\"LABEL\"].astype(int).values - 1\n",
    "%time xclone = XClone(A_G_prime, D_G_prime, A_G, D_G, I_G_prime, CNV_prime, T_max)\n",
    "# %time xclone.do_gibbs_sampling_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init loglik time: 1.2457890510559082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49e282a899b483686efacab422d80a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 — labelling update!\n",
      "-6951815.771568522 -6809723.779732377\n",
      "Iteration 1 — labelling update!\n",
      "-6809723.779732377 -6638900.113386817\n",
      "Iteration 2 — labelling update!\n",
      "-6638900.113386817 -6382111.483270387\n",
      "Iteration 4 — labelling update!\n",
      "-6382111.483270387 -6311827.888932517\n",
      "Iteration 5 — labelling update!\n",
      "-6311827.888932517 -6308985.006400545\n",
      "Iteration 6 — labelling update!\n",
      "-6308985.006400545 -6291860.285992733\n",
      "Iteration 7 — labelling update!\n",
      "-6291860.285992733 -6248854.026708256\n",
      "Iteration 9 — labelling update!\n",
      "-6248854.026708256 -6229739.118621012\n",
      "Iteration 11 — labelling update!\n",
      "-6229739.118621012 -6194478.171499716\n",
      "Iteration 18 — labelling update!\n",
      "-6194478.171499716 -6186882.550636066\n",
      "Iteration 23 — labelling update!\n",
      "-6186882.550636066 -6171777.392886904\n",
      "Iteration 26 — labelling update!\n",
      "-6171777.392886904 -6140420.936226614\n",
      "Iteration 31 — labelling update!\n",
      "-6140420.936226614 -6132372.342925662\n",
      "Iteration 35 — labelling update!\n",
      "-6132372.342925662 -6113477.518528445\n",
      "Iteration 51 — labelling update!\n",
      "-6113477.518528445 -6107266.296654116\n",
      "Iteration 66 — labelling update!\n",
      "-6107266.296654116 -6046707.086057585\n",
      "Iteration 74 — labelling update!\n",
      "-6046707.086057585 -6038684.545875066\n",
      "Iteration 158 — labelling update!\n",
      "-6038684.545875066 -6011244.041982522\n",
      "Iteration 243 — labelling update!\n",
      "-6011244.041982522 -6002707.149438678\n",
      "Iteration 249 — labelling update!\n",
      "-6002707.149438678 -5998894.343908385\n"
     ]
    }
   ],
   "source": [
    "%time xclone.do_gibbs_sampling(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loglikelihood(X_G_prime, X_G):\n",
    "    return (\n",
    "        np.sum([\n",
    "            cell_loglikelihood(cell_id, A_G_prime[:, cell_id], D_G_prime[:, cell_id], X_G_prime[:, cell_id])\n",
    "            for cell_id in range(M)#tqdm_notebook(range(M_prime), \"scDNA: computing log L\")\n",
    "        ]) + np.sum([\n",
    "            cell_loglikelihood(cell_id, A_G[:, cell_id], D_G[:, cell_id], X_G[:, cell_id])\n",
    "            for cell_id in range(M)#tqdm_notebook(range(M), \"scRNA: computing log L\")\n",
    "        ])   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prior total loglikelihood:\t -400198.14423451526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v390v/.conda/envs/mb/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcc6983bd6341af95da512f503d3380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='computing posterior', max=1, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd8a88217e8478b953680ed2bfe66a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=268), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684219fbbbb6403db27be115371013d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial posterior total loglikelihood:\t -374280.8431529163\n"
     ]
    }
   ],
   "source": [
    "prior_total_loglikelihood = total_loglikelihood(X_G_prime, X_G)\n",
    "print(\"Initial prior total loglikelihood:\\t\", prior_total_loglikelihood)\n",
    "for block_id, cnv_code in tqdm_notebook(cartesian(range(N_G), range(tau.shape[0])), \"computing posterior\"):\n",
    "    a_prime = A_G_prime[block_id, :]\n",
    "    d_prime = D_G_prime[block_id, :]\n",
    "    h_prime_mask = H_G_prime[block_id, :] == cnv_code\n",
    "    \n",
    "    a = A_G[block_id, :]\n",
    "    d = D_G[block_id, :]\n",
    "    h_mask = H_G[block_id, :] == cnv_code\n",
    "    \n",
    "    u = np.nansum(np.hstack((a_prime * h_prime_mask, a * h_mask)))  \n",
    "    v = np.nansum(np.hstack(((d_prime - a_prime) * h_prime_mask, (d - a) * h_mask)))\n",
    "\n",
    "    assert u >= 0, v >= 0\n",
    "    Alpha_G[block_id, cnv_code] += u\n",
    "    Beta_G[block_id, cnv_code] += v\n",
    "\n",
    "Theta_G = sps.beta(a=Alpha_G, b=Beta_G).rvs(size=Alpha_G.shape)  \n",
    "    \n",
    "for cell_id in tqdm_notebook(range(M_prime)):\n",
    "    not_na_mask = ~np.isnan(H_G_prime[:, cell_id])\n",
    "    X_G_prime[not_na_mask, cell_id] = Theta_G[not_na_mask, \n",
    "                                              H_G_prime[not_na_mask, cell_id].astype(int)]\n",
    "\n",
    "for cell_id in tqdm_notebook(range(M)):\n",
    "    not_na_mask = ~np.isnan(H_G[:, cell_id])\n",
    "    X_G[not_na_mask, cell_id] = Theta_G[not_na_mask, \n",
    "                                        H_G[not_na_mask, cell_id].astype(int)]\n",
    "    \n",
    "posterior_total_loglikelihood = total_loglikelihood(X_G_prime, X_G)\n",
    "print(\"Initial posterior total loglikelihood:\\t\", posterior_total_loglikelihood)\n",
    "# assert posterior_total_loglikelihood > prior_total_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-374280.8431529163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b6acd344af47409f5741381533ea48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sampling iteration', max=10000, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% changed:\t 90.0\n",
      "Counter({9: 2, 8: 2, 6: 2, 5: 1, 7: 1, 1: 1, 2: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/v390v/.conda/envs/mb/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:\t loglikelihood of -382604.71953687764\n",
      "% changed:\t 100.0\n",
      "Counter({3: 2, 1: 2, 8: 1, 2: 1, 5: 1, 9: 1, 4: 1, 6: 1})\n",
      "Iter 1:\t loglikelihood of -384216.7253803791\n",
      "% changed:\t 90.0\n",
      "Counter({1: 2, 5: 2, 6: 2, 2: 1, 7: 1, 8: 1, 9: 1})\n",
      "Iter 2:\t loglikelihood of -385023.0907452116\n",
      "% changed:\t 80.0\n",
      "Counter({6: 3, 7: 2, 5: 2, 2: 1, 3: 1, 1: 1})\n",
      "Iter 3:\t loglikelihood of -374947.07764005905\n",
      "% changed:\t 90.0\n",
      "Counter({3: 3, 5: 2, 7: 1, 1: 1, 9: 1, 6: 1, 2: 1})\n",
      "Iter 4:\t loglikelihood of -373442.07391015114\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 80.0\n",
      "Counter({5: 3, 7: 3, 8: 2, 9: 1, 2: 1})\n",
      "Iter 5:\t loglikelihood of -381789.09300347936\n",
      "% changed:\t 90.0\n",
      "Counter({5: 4, 2: 4, 6: 1, 8: 1})\n",
      "Iter 6:\t loglikelihood of -397017.06126588525\n",
      "% changed:\t 100.0\n",
      "Counter({2: 2, 8: 2, 9: 2, 3: 1, 5: 1, 7: 1, 6: 1})\n",
      "Iter 7:\t loglikelihood of -372113.6197365558\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 100.0\n",
      "Counter({6: 3, 5: 2, 8: 2, 4: 1, 3: 1, 1: 1})\n",
      "Iter 8:\t loglikelihood of -387348.3458155921\n",
      "% changed:\t 100.0\n",
      "Counter({2: 2, 7: 2, 4: 2, 1: 1, 9: 1, 5: 1, 6: 1})\n",
      "Iter 9:\t loglikelihood of -370783.4860132851\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 90.0\n",
      "Counter({3: 4, 2: 3, 7: 1, 5: 1, 6: 1})\n",
      "Iter 10:\t loglikelihood of -366393.7310065485\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 90.0\n",
      "Counter({6: 2, 8: 2, 2: 2, 7: 2, 4: 1, 1: 1})\n",
      "Iter 11:\t loglikelihood of -354652.4231740141\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 80.0\n",
      "Counter({6: 2, 8: 2, 2: 2, 5: 2, 1: 2})\n",
      "Iter 12:\t loglikelihood of -362208.69023155665\n",
      "% changed:\t 100.0\n",
      "Counter({3: 3, 8: 2, 9: 2, 6: 1, 5: 1, 1: 1})\n",
      "Iter 13:\t loglikelihood of -354620.49962442834\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 90.0\n",
      "Counter({6: 3, 1: 2, 9: 1, 5: 1, 8: 1, 4: 1, 3: 1})\n",
      "Iter 14:\t loglikelihood of -359592.00637376163\n",
      "% changed:\t 80.0\n",
      "Counter({6: 3, 9: 2, 3: 1, 2: 1, 1: 1, 4: 1, 7: 1})\n",
      "Iter 15:\t loglikelihood of -355874.26803916297\n",
      "% changed:\t 80.0\n",
      "Counter({8: 3, 2: 2, 6: 2, 4: 1, 5: 1, 7: 1})\n",
      "Iter 16:\t loglikelihood of -352397.47457805614\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 90.0\n",
      "Counter({1: 3, 9: 2, 8: 1, 6: 1, 3: 1, 7: 1, 5: 1})\n",
      "Iter 17:\t loglikelihood of -353304.5639578159\n",
      "% changed:\t 90.0\n",
      "Counter({2: 2, 6: 2, 7: 2, 3: 2, 1: 1, 4: 1})\n",
      "Iter 18:\t loglikelihood of -349584.9503834946\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 80.0\n",
      "Counter({3: 3, 5: 2, 2: 2, 1: 1, 7: 1, 4: 1})\n",
      "Iter 19:\t loglikelihood of -375401.56557157496\n",
      "% changed:\t 80.0\n",
      "Counter({3: 2, 7: 2, 8: 2, 6: 2, 1: 1, 9: 1})\n",
      "Iter 20:\t loglikelihood of -342177.2990037082\n",
      "UPDATE ASSIGNMENT\n",
      "% changed:\t 100.0\n",
      "Counter({1: 3, 3: 2, 2: 2, 4: 1, 6: 1, 5: 1})\n",
      "Iter 21:\t loglikelihood of -351834.54229378165\n",
      "% changed:\t 90.0\n",
      "Counter({7: 2, 5: 2, 4: 2, 8: 2, 6: 1, 3: 1})\n",
      "Iter 22:\t loglikelihood of -364992.6555836975\n",
      "% changed:\t 80.0\n",
      "Counter({6: 2, 2: 2, 7: 2, 8: 1, 3: 1, 5: 1, 1: 1})\n",
      "Iter 23:\t loglikelihood of -350211.65228198154\n",
      "% changed:\t 100.0\n",
      "Counter({6: 3, 2: 3, 1: 2, 9: 1, 8: 1})\n",
      "Iter 24:\t loglikelihood of -355091.4466351727\n",
      "% changed:\t 90.0\n",
      "Counter({8: 3, 3: 2, 5: 1, 6: 1, 2: 1, 1: 1, 9: 1})\n",
      "Iter 25:\t loglikelihood of -361709.35685314774\n",
      "% changed:\t 80.0\n",
      "Counter({9: 5, 8: 1, 1: 1, 3: 1, 6: 1, 5: 1})\n",
      "Iter 26:\t loglikelihood of -350377.83196311555\n",
      "% changed:\t 100.0\n",
      "Counter({9: 3, 6: 2, 3: 2, 5: 1, 8: 1, 4: 1})\n",
      "Iter 27:\t loglikelihood of -373989.20089401427\n",
      "% changed:\t 90.0\n",
      "Counter({2: 3, 5: 2, 1: 2, 8: 2, 6: 1})\n",
      "Iter 28:\t loglikelihood of -374119.1622129852\n",
      "% changed:\t 80.0\n",
      "Counter({3: 3, 9: 3, 2: 2, 1: 1, 6: 1})\n",
      "Iter 29:\t loglikelihood of -351451.12085143186\n",
      "% changed:\t 90.0\n",
      "Counter({2: 4, 3: 3, 6: 2, 1: 1})\n",
      "Iter 30:\t loglikelihood of -351899.23335246695\n",
      "% changed:\t 100.0\n",
      "Counter({5: 3, 8: 2, 2: 2, 7: 1, 3: 1, 4: 1})\n",
      "Iter 31:\t loglikelihood of -377240.4027306229\n",
      "% changed:\t 100.0\n",
      "Counter({2: 3, 5: 2, 3: 2, 4: 1, 7: 1, 1: 1})\n",
      "Iter 32:\t loglikelihood of -368748.25688885327\n",
      "% changed:\t 90.0\n",
      "Counter({8: 2, 2: 2, 5: 2, 4: 1, 7: 1, 9: 1, 1: 1})\n",
      "Iter 33:\t loglikelihood of -355281.9994137584\n",
      "% changed:\t 80.0\n",
      "Counter({2: 3, 1: 2, 6: 2, 9: 1, 8: 1, 7: 1})\n",
      "Iter 34:\t loglikelihood of -351815.6813125225\n",
      "% changed:\t 80.0\n",
      "Counter({9: 3, 3: 3, 5: 1, 6: 1, 1: 1, 7: 1})\n",
      "Iter 35:\t loglikelihood of -361846.95932128537\n",
      "% changed:\t 100.0\n",
      "Counter({3: 2, 7: 2, 5: 2, 9: 1, 1: 1, 2: 1, 8: 1})\n",
      "Iter 36:\t loglikelihood of -353833.3139557815\n",
      "% changed:\t 90.0\n",
      "Counter({3: 2, 1: 2, 6: 2, 9: 2, 5: 1, 2: 1})\n",
      "Iter 37:\t loglikelihood of -373396.58668363397\n",
      "% changed:\t 90.0\n",
      "Counter({7: 5, 1: 2, 6: 1, 5: 1, 2: 1})\n",
      "Iter 38:\t loglikelihood of -350835.6929208592\n",
      "% changed:\t 100.0\n",
      "Counter({3: 3, 9: 2, 8: 1, 2: 1, 5: 1, 7: 1, 6: 1})\n",
      "Iter 39:\t loglikelihood of -360036.41321909556\n",
      "% changed:\t 70.0\n",
      "Counter({8: 2, 9: 2, 4: 2, 6: 1, 5: 1, 2: 1, 1: 1})\n",
      "Iter 40:\t loglikelihood of -361135.2870361522\n",
      "% changed:\t 100.0\n",
      "Counter({1: 3, 6: 3, 9: 2, 5: 1, 4: 1})\n",
      "Iter 41:\t loglikelihood of -366461.4783124287\n",
      "% changed:\t 90.0\n",
      "Counter({8: 4, 2: 2, 9: 1, 3: 1, 1: 1, 7: 1})\n",
      "Iter 42:\t loglikelihood of -351034.5577478829\n",
      "% changed:\t 90.0\n",
      "Counter({6: 2, 1: 2, 5: 2, 3: 2, 9: 1, 8: 1})\n",
      "Iter 43:\t loglikelihood of -357450.7893429416\n",
      "% changed:\t 70.0\n",
      "Counter({9: 4, 8: 2, 6: 2, 3: 1, 5: 1})\n",
      "Iter 44:\t loglikelihood of -351625.52691655315\n",
      "% changed:\t 90.0\n",
      "Counter({6: 5, 4: 1, 9: 1, 2: 1, 3: 1, 5: 1})\n",
      "Iter 45:\t loglikelihood of -352242.7106104266\n",
      "% changed:\t 90.0\n",
      "Counter({6: 3, 5: 2, 9: 1, 7: 1, 8: 1, 2: 1, 1: 1})\n",
      "Iter 46:\t loglikelihood of -383024.3586871814\n",
      "% changed:\t 80.0\n",
      "Counter({9: 2, 3: 2, 2: 2, 6: 2, 7: 1, 8: 1})\n",
      "Iter 47:\t loglikelihood of -351344.09429181204\n",
      "% changed:\t 80.0\n",
      "Counter({7: 3, 6: 2, 9: 2, 4: 2, 8: 1})\n",
      "Iter 48:\t loglikelihood of -348489.17253313796\n",
      "% changed:\t 100.0\n",
      "Counter({7: 2, 4: 2, 5: 2, 1: 1, 3: 1, 8: 1, 9: 1})\n",
      "Iter 49:\t loglikelihood of -354735.63978904847\n",
      "% changed:\t 90.0\n",
      "Counter({2: 3, 6: 3, 7: 1, 9: 1, 3: 1, 4: 1})\n",
      "Iter 50:\t loglikelihood of -350272.80990401946\n",
      "% changed:\t 100.0\n",
      "Counter({5: 3, 8: 2, 9: 1, 3: 1, 7: 1, 6: 1, 1: 1})\n",
      "Iter 51:\t loglikelihood of -383019.62134310184\n",
      "% changed:\t 80.0\n",
      "Counter({8: 2, 5: 2, 4: 2, 6: 2, 3: 1, 1: 1})\n",
      "Iter 52:\t loglikelihood of -377644.8419660876\n",
      "% changed:\t 80.0\n",
      "Counter({1: 3, 8: 2, 5: 2, 6: 2, 2: 1})\n",
      "Iter 53:\t loglikelihood of -373459.68082581926\n",
      "% changed:\t 100.0\n",
      "Counter({5: 3, 7: 2, 4: 1, 3: 1, 9: 1, 1: 1, 6: 1})\n",
      "Iter 54:\t loglikelihood of -353874.2030103225\n",
      "% changed:\t 80.0\n",
      "Counter({8: 3, 5: 3, 6: 2, 9: 1, 4: 1})\n",
      "Iter 55:\t loglikelihood of -364558.8026123678\n",
      "% changed:\t 100.0\n",
      "Counter({9: 3, 1: 2, 7: 2, 6: 1, 3: 1, 2: 1})\n",
      "Iter 56:\t loglikelihood of -352535.6300204191\n",
      "% changed:\t 90.0\n",
      "Counter({9: 3, 6: 1, 1: 1, 8: 1, 4: 1, 2: 1, 7: 1, 3: 1})\n",
      "Iter 57:\t loglikelihood of -353940.13249731914\n",
      "% changed:\t 70.0\n",
      "Counter({8: 2, 7: 2, 6: 2, 9: 1, 2: 1, 5: 1, 1: 1})\n",
      "Iter 58:\t loglikelihood of -358658.81420760904\n",
      "% changed:\t 80.0\n",
      "Counter({9: 2, 7: 2, 3: 2, 2: 2, 5: 1, 6: 1})\n",
      "Iter 59:\t loglikelihood of -357707.8124213425\n",
      "% changed:\t 70.0\n",
      "Counter({5: 3, 2: 2, 4: 2, 6: 2, 3: 1})\n",
      "Iter 60:\t loglikelihood of -381109.2995021298\n",
      "% changed:\t 80.0\n",
      "Counter({7: 3, 5: 2, 1: 2, 3: 1, 9: 1, 6: 1})\n",
      "Iter 61:\t loglikelihood of -374595.7694768127\n",
      "% changed:\t 90.0\n",
      "Counter({1: 3, 5: 2, 7: 2, 4: 1, 3: 1, 6: 1})\n",
      "Iter 62:\t loglikelihood of -366514.9834228074\n",
      "% changed:\t 100.0\n",
      "Counter({5: 5, 9: 2, 1: 1, 6: 1, 4: 1})\n",
      "Iter 63:\t loglikelihood of -412781.51882122445\n",
      "% changed:\t 90.0\n",
      "Counter({9: 3, 6: 2, 5: 2, 3: 1, 7: 1, 1: 1})\n",
      "Iter 64:\t loglikelihood of -364892.5553815074\n",
      "% changed:\t 80.0\n",
      "Counter({3: 3, 1: 2, 2: 2, 9: 1, 4: 1, 5: 1})\n",
      "Iter 65:\t loglikelihood of -352635.31990808423\n",
      "% changed:\t 90.0\n",
      "Counter({1: 3, 2: 3, 3: 1, 8: 1, 6: 1, 5: 1})\n",
      "Iter 66:\t loglikelihood of -350574.52098781354\n",
      "% changed:\t 70.0\n",
      "Counter({7: 5, 3: 2, 5: 2, 1: 1})\n",
      "Iter 67:\t loglikelihood of -367666.3268281759\n",
      "% changed:\t 80.0\n",
      "Counter({2: 3, 6: 2, 3: 2, 1: 2, 9: 1})\n",
      "Iter 68:\t loglikelihood of -351843.3222241951\n",
      "% changed:\t 100.0\n",
      "Counter({7: 2, 5: 2, 3: 2, 1: 2, 9: 1, 6: 1})\n",
      "Iter 69:\t loglikelihood of -367764.5516250434\n",
      "% changed:\t 100.0\n",
      "Counter({9: 4, 3: 1, 7: 1, 5: 1, 2: 1, 8: 1, 4: 1})\n",
      "Iter 70:\t loglikelihood of -356606.1732938341\n",
      "% changed:\t 100.0\n",
      "Counter({2: 3, 6: 3, 1: 2, 3: 1, 5: 1})\n",
      "Iter 71:\t loglikelihood of -353803.47508388\n",
      "% changed:\t 90.0\n",
      "Counter({2: 4, 9: 3, 6: 1, 4: 1, 8: 1})\n",
      "Iter 72:\t loglikelihood of -353465.61089624406\n",
      "% changed:\t 100.0\n",
      "Counter({9: 4, 3: 1, 4: 1, 2: 1, 7: 1, 8: 1, 5: 1})\n",
      "Iter 73:\t loglikelihood of -352296.1942096808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% changed:\t 80.0\n",
      "Counter({6: 3, 1: 2, 3: 2, 9: 1, 7: 1, 8: 1})\n",
      "Iter 74:\t loglikelihood of -350785.98695306387\n",
      "% changed:\t 80.0\n",
      "Counter({5: 2, 8: 2, 1: 1, 4: 1, 7: 1, 3: 1, 9: 1, 6: 1})\n",
      "Iter 75:\t loglikelihood of -362701.4125440626\n",
      "% changed:\t 100.0\n",
      "Counter({2: 3, 1: 3, 5: 2, 8: 1, 3: 1})\n",
      "Iter 76:\t loglikelihood of -351877.7436479023\n",
      "% changed:\t 80.0\n",
      "Counter({6: 2, 8: 2, 1: 2, 5: 1, 7: 1, 2: 1, 9: 1})\n",
      "Iter 77:\t loglikelihood of -360522.3832776577\n",
      "% changed:\t 100.0\n",
      "Counter({8: 2, 2: 2, 5: 2, 9: 1, 6: 1, 4: 1, 1: 1})\n",
      "Iter 78:\t loglikelihood of -366165.3069774543\n",
      "% changed:\t 90.0\n",
      "Counter({1: 2, 3: 2, 7: 1, 5: 1, 2: 1, 9: 1, 6: 1, 8: 1})\n",
      "Iter 79:\t loglikelihood of -356649.6772357491\n",
      "% changed:\t 70.0\n",
      "Counter({7: 6, 2: 1, 4: 1, 3: 1, 5: 1})\n",
      "Iter 80:\t loglikelihood of -343752.3162429412\n",
      "% changed:\t 80.0\n",
      "Counter({1: 4, 5: 3, 3: 1, 9: 1, 6: 1})\n",
      "Iter 81:\t loglikelihood of -389668.9657983347\n",
      "% changed:\t 90.0\n",
      "Counter({3: 3, 5: 2, 1: 2, 6: 1, 8: 1, 9: 1})\n",
      "Iter 82:\t loglikelihood of -351862.2362852215\n",
      "% changed:\t 100.0\n",
      "Counter({2: 3, 1: 3, 4: 1, 5: 1, 9: 1, 7: 1})\n",
      "Iter 83:\t loglikelihood of -358651.4444370407\n",
      "% changed:\t 90.0\n",
      "Counter({1: 4, 3: 2, 7: 2, 6: 1, 5: 1})\n",
      "Iter 84:\t loglikelihood of -357860.8178656895\n",
      "% changed:\t 80.0\n",
      "Counter({2: 3, 9: 2, 3: 1, 1: 1, 7: 1, 5: 1, 4: 1})\n",
      "Iter 85:\t loglikelihood of -351874.6493441138\n",
      "% changed:\t 90.0\n",
      "Counter({5: 3, 3: 2, 1: 1, 4: 1, 6: 1, 9: 1, 7: 1})\n",
      "Iter 86:\t loglikelihood of -374568.2618720976\n",
      "% changed:\t 90.0\n",
      "Counter({3: 4, 5: 2, 6: 1, 1: 1, 8: 1, 7: 1})\n",
      "Iter 87:\t loglikelihood of -361857.8756686"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10004 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_alpha_beta(block_id, cnv_code, Theta_G, Alpha_G, Beta_G, H_G, changed_mask):\n",
    "    a = A_G[block_id, changed_mask]\n",
    "    d = D_G[block_id, changed_mask]\n",
    "    h_mask = H_G[block_id, changed_mask] == cnv_code\n",
    "    \n",
    "    u = np.nansum(a * h_mask)\n",
    "    v = np.nansum((d - a) * h_mask)\n",
    "    assert u >= 0, v >= 0\n",
    "    \n",
    "    new_alpha = Alpha_G[block_id, cnv_code] + u\n",
    "    new_beta = Beta_G[block_id, cnv_code] + v\n",
    "    return new_alpha, new_beta\n",
    "\n",
    "Alpha_G_prior = Alpha_G.copy()\n",
    "Beta_G_prior = Beta_G.copy()\n",
    "\n",
    "print(posterior_total_loglikelihood)\n",
    "\n",
    "for ITER in tqdm_notebook(range(10000), \"sampling iteration\"):\n",
    "    new_I_G = np.array([update_I_G(cell_id, Theta_G) for cell_id in range(M)])#tqdm_notebook(range(M), \"updating I_G\")])\n",
    "#     new_I_G = \\\n",
    "#        np.array(Parallel(16)(\n",
    "#            delayed(update_I_G)(cell_id, Theta_G)\n",
    "#            for cell_id in tqdm_notebook(range(M), \"updating I_G\")\n",
    "#        ))\n",
    "    \n",
    "    changed_mask = new_I_G != I_G\n",
    "    print(\"% changed:\\t\", 100 * np.mean(changed_mask))\n",
    "    \n",
    "    print(Counter(new_I_G + 1))\n",
    "#     plt.hist(new_I_G, bins=np.arange(K+1))\n",
    "#     plt.show()\n",
    "    \n",
    "    new_alpha_beta = np.array([\n",
    "        update_alpha_beta(block_id, cnv_code, Theta_G, Alpha_G, Beta_G, H_G, changed_mask)\n",
    "        for block_id, cnv_code in cartesian(\n",
    "            range(N_G), range(tau.shape[0])\n",
    "        )#, \"computing posterior\")\n",
    "    ])\n",
    "#     \\\n",
    "#         np.vstack(Parallel(16)(\n",
    "#             delayed(update_alpha_beta)(block_id, cnv_code, Theta_G, Alpha_G, Beta_G, H_G, changed_mask)\n",
    "#             for block_id, cnv_code in tqdm_notebook(cartesian(\n",
    "#                 range(N_G), range(tau.shape[0])\n",
    "#             ), \"computing posterior\")\n",
    "#         ))\n",
    "    \n",
    "    new_Alpha_G = new_alpha_beta[:, 0].reshape(Alpha_G.shape)\n",
    "    new_Beta_G = new_alpha_beta[:, 1].reshape(Alpha_G.shape)\n",
    "    new_Theta_G = sps.beta(a=new_Alpha_G, b=new_Beta_G).rvs(size=Alpha_G.shape)\n",
    "    \n",
    "#     np.vstack(update_alpha_beta(block_id, cnv_code)\n",
    "#         for block_id, cnv_code in tqdm_notebook(cartesian(\n",
    "#             range(N_G), range(tau.shape[0])\n",
    "#         ), \"computing| posterior\"))\n",
    "\n",
    "\n",
    "    new_H_G = H_G.copy()\n",
    "    new_X_G = X_G.copy()\n",
    "    for cell_id in range(M):#tqdm_notebook(range(M), \"updating H_G and X_G\"):\n",
    "        new_H_G[:, cell_id] = T[:, new_I_G[cell_id]]\n",
    "        not_na_mask = ~np.isnan(new_H_G[:, cell_id])\n",
    "        new_X_G[not_na_mask, cell_id] = new_Theta_G[\n",
    "            not_na_mask, \n",
    "            new_H_G[not_na_mask, cell_id].astype(int)\n",
    "        ]\n",
    "        \n",
    "    curr_loglikelihood = total_loglikelihood(X_G_prime, new_X_G)\n",
    " \n",
    "    print(f\"Iter {ITER}:\\t loglikelihood of {curr_loglikelihood}\")\n",
    "    \n",
    "    if curr_loglikelihood > posterior_total_loglikelihood:\n",
    "        print(\"UPDATE ASSIGNMENT\")\n",
    "        posterior_total_loglikelihood = curr_loglikelihood\n",
    "        I_G = new_I_G.copy()\n",
    "        Alpha_G = new_Alpha_G.copy()\n",
    "        Beta_G = new_Beta_G.copy()\n",
    "        Theta_G = new_Theta_G.copy()\n",
    "    #     Theta_G[Theta_G == 0] = 0.01\n",
    "    #     Theta_G[Theta_G == 1] = 0.99\n",
    "#         print(\"Plotting report\")\n",
    "        classification_report(\n",
    "            data[\"scRNA\"][\"clustering\"].LABEL.apply(lambda i: I_G[i] + 1),#I_G + 1,\n",
    "            title=f\"XClone label assignment, iteration {ITER},\"\\\n",
    "                    f\" loglikelihood {posterior_total_loglikelihood} \\n\"\\\n",
    "                    \"evo_dist_9 clustering of scDNA,\\n\"\\\n",
    "                    \"seurat clustering of scRNA,\\n\"\\\n",
    "                    f\"{N_G} haplotype blocks\",\n",
    "            outfile=f\"{workspace['scRNA'].img_dir}/xclone/\"\\\n",
    "                    f\"iter_{ITER}_loglikelihood_{posterior_total_loglikelihood}.png\"\n",
    "        )\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-xclone] *",
   "language": "python",
   "name": "conda-env-.conda-xclone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
